Metadata-Version: 2.4
Name: driftguard-video-pipeline
Version: 0.1.0
Summary: Basic drift-aware long-video generation pipeline scaffold.
Author: SceneWeaver Team
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: PyYAML>=6.0
Requires-Dist: numpy>=1.24
Provides-Extra: dev
Requires-Dist: pytest>=8.0; extra == "dev"
Requires-Dist: ruff>=0.6; extra == "dev"
Provides-Extra: vision
Requires-Dist: Pillow>=10.0; extra == "vision"
Requires-Dist: transformers>=4.41; extra == "vision"
Requires-Dist: torch>=2.1; extra == "vision"
Provides-Extra: video
Requires-Dist: imageio>=2.34; extra == "video"
Requires-Dist: diffusers>=0.30; extra == "video"
Requires-Dist: accelerate>=0.30; extra == "video"
Dynamic: license-file

# driftguard-video-pipeline

Drift-aware architecture for long-form text-to-video generation with:
- retrieval + canon building
- storyline planning + per-window prompting
- windowed generation
- critics (drift/canon/prompt)
- iterative refine loop

## Structure
```text
src/driftguard/
  cli.py
  pipeline.py
  retrieval/{fetch,clean,chunk,index}.py
  planning/{canon,storyboard,prompts}.py
  generation/{video,windowing,seeds}.py
  critics/{drift,canon,prompt}.py
  refine/{loop,budget}.py
  utils/{io,logging,types}.py
```

## Install
```bash
pip install -r requirements.txt
pip install -e .
```

## Quick Start (Basic Working Pipeline)
Use the committed storyline sample:
```bash
driftguard run --config configs/default.yaml --storyline_file data/examples/storyline.txt --dry_run
```

This writes:
- `outputs/runs/<run_id>/run_log.jsonl`
- `outputs/runs/<run_id>/run_summary.json`

## Legacy Components Kept
Existing components are still available and adapted as backends:
- `director_llm/scene_director.py`
- `memory_module/embedding_memory.py`
- `video_backbone/wan_backbone.py`

## Cluster Note
For real video generation with Wan 2.0 14B, run on CUDA cluster nodes and set model/runtime parameters in `configs/models.yaml` or CLI flags.
